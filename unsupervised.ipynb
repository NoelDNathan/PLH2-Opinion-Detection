{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# Define una funci칩n para calcular la polaridad de un synset\n",
    "def synset_polarity(synset):\n",
    "    senti_synset = swn.senti_synset(synset.name())\n",
    "    if not senti_synset:\n",
    "        # Si el synset no tiene entrada en SentiWordNet, devuelve polaridad neutra\n",
    "        return 0\n",
    "    else:\n",
    "        # Calcula la polaridad positiva y negativa del synset\n",
    "        pos_score = senti_synset.pos_score()\n",
    "        neg_score = senti_synset.neg_score()\n",
    "        # Calcula la polaridad total normalizada\n",
    "        polarity = (pos_score - neg_score) / (pos_score + neg_score + 0.001)\n",
    "        return polarity\n",
    "\n",
    "# Define una funci칩n para obtener los synsets y polaridades de cada adjetivo en un conjunto de texto\n",
    "def get_polarities(text, tags = ['JJ', 'JJR', 'JJS']):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    important_words = []\n",
    "\n",
    "    for word, pos in nltk.pos_tag(words):\n",
    "        if pos in tags: \n",
    "            important_words.append((word, pos, wn.synsets(word)))\n",
    "\n",
    "    polarities = []\n",
    "\n",
    "    for word, pos, synsets in important_words:\n",
    "        polarity = 0\n",
    "        count = 0\n",
    "\n",
    "        for synset in synsets:\n",
    "            # Calcula la polaridad de cada synset y la suma\n",
    "            polarity += synset_polarity(synset)\n",
    "            count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            # Calcula la polaridad media\n",
    "            polarity /= count\n",
    "            \n",
    "        # A침ade la polaridad media a la lista de polaridades\n",
    "        polarities.append(polarity)\n",
    "    return polarities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carga los datos\n",
    "df = pd.read_csv('reviews.csv')\n",
    "X = df.drop('sentiment', axis=1)\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.59\n",
      "Precision:  0.5623100303951368\n",
      "Recall:  0.9024390243902439\n",
      "F1:  0.6928838951310862\n"
     ]
    }
   ],
   "source": [
    "adj = ['JJ', 'JJR', 'JJS']\n",
    "noun = ['NN', 'NNS']\n",
    "verb = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "adv = ['RB', 'RBR', 'RBS']\n",
    "\n",
    "noun_adj_adv = noun + adj + adv\n",
    "noun_adj_adv_verb = noun + adj + adv + verb\n",
    "\n",
    "FN = 0 # False Negative\n",
    "FP = 0 # False Positive\n",
    "TP = 0 # True Positive\n",
    "TN = 0 # True Negative\n",
    "\n",
    "# Itera sobre los datos de test\n",
    "for text, pred in zip(X_test['review'], y_test):\n",
    "    polarities = get_polarities(text, noun_adj_adv)     \n",
    "    output = 0\n",
    "\n",
    "    # Si la suma de las polaridades es positiva, la predicci칩n es positiva\n",
    "    if sum(polarities) > 0:\n",
    "        output = 1\n",
    "    \n",
    "    \n",
    "    if output == 1 and pred:\n",
    "        TP += 1\n",
    "    elif output == 1 and not pred:\n",
    "        FP += 1\n",
    "    elif output == 0 and pred:\n",
    "        FN += 1\n",
    "    elif output == 0 and not pred:\n",
    "        TN += 1\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incandcent JJ\n"
     ]
    }
   ],
   "source": [
    "text = \"I hate the movie. It was incandcent\"\n",
    "tags = ['JJ']\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "important_words = []\n",
    "for word, pos in nltk.pos_tag(words):\n",
    "    if pos in adj:\n",
    "        print(word, pos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
